{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1jHXbWLhZnTmPHhH35_iqUGRsRcQl0AKY","authorship_tag":"ABX9TyP4WuwFoPF9BQxb0LSS2VOZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UxSr3PfossrN"},"outputs":[],"source":["import pandas as pd\n","import html\n","import contractions\n","import unicodedata"]},{"cell_type":"code","source":["pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3I9X5zfNupVu","executionInfo":{"status":"ok","timestamp":1722953519484,"user_tz":-330,"elapsed":8770,"user":{"displayName":"Abhishek maher","userId":"17060706371112675718"}},"outputId":"dc9dc7b6-ef2f-4450-a92d-5de389af31f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.12.2)\n","Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.12.1\n"]}]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/emojien/Data/emojitweets-01-04-2018.txt', 'r') as file: # Downloaded the data file from https://www.kaggle.com/datasets/rexhaif/emojifydata-en\n","    tweets = file.readlines()\n","\n","# Create a DataFrame\n","bigdf = pd.DataFrame(tweets, columns=['tweet'])"],"metadata":{"id":"awKCSQROtErb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del tweets"],"metadata":{"id":"9BHmWK1Y0Fs8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import emoji\n","import re\n","\n","def extract_emojis(text): #function to seperate emojis and text\n","    emojis = emoji.distinct_emoji_list(text)\n","    text = emoji.replace_emoji(text, replace='')\n","    text_without_emojis = ' '.join(text.split())\n","    return text_without_emojis, emojis"],"metadata":{"id":"kkT3pPsSt-cB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = bigdf.sample(1000000) # Choosing a random sample of 10M texts"],"metadata":{"id":"Rk2-Rmv65Q0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[['tweet', 'emojis']] = df['tweet'].apply(lambda x: pd.Series(extract_emojis(x)))"],"metadata":{"id":"BvpAj7bJxKPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emojis_array = df.explode('emojis').dropna()['emojis']"],"metadata":{"id":"Jtln49rdy824"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emojis_array.value_counts()[50:100]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnQJr_a36R2c","executionInfo":{"status":"ok","timestamp":1722957551344,"user_tz":-330,"elapsed":567,"user":{"displayName":"Abhishek maher","userId":"17060706371112675718"}},"outputId":"2369cd7f-bc5d-456c-ec76-62da080befed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["emojis\n","😱        5676\n","😏        5548\n","💔        5503\n","🌹        5496\n","💋        5430\n","💘        5410\n","😈        5401\n","🖤        5244\n","☺️       4971\n","👑        4935\n","🙃        4900\n","💦        4863\n","👇        4828\n","©        4664\n","🌸        4625\n","😌        4624\n","⚡        4596\n","💫        4544\n","😋        4536\n","💎        4428\n","😔        4401\n","😒        4193\n","📷        3918\n","😆        3842\n","➡️       3799\n","😜        3773\n","😀        3765\n","🎂        3722\n","😤        3704\n","📸        3637\n","⭐        3544\n","💰        3536\n","🙈        3525\n","😄        3520\n","🤷🏽‍♀️    3502\n","🔴        3465\n","🤤        3428\n","⚽        3424\n","😫        3412\n","🙂        3324\n","🤧        3272\n","❗        3232\n","😇        3211\n","🎁        3200\n","🎥        3127\n","☀️       3127\n","🤪        3109\n","❄️       3005\n","🙏🏾       2998\n","🚀        2990\n","Name: count, dtype: int64"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["\"\"\"\n","1. lower case\n","2. remove html entities\n","3. remove links\n","4. remove @\n","2. remove /\n","4. convert contractions to single words\n","2. remove punc\n","3. remove numbers and symbols\n","5. lemmatize\n","observations: html entities are not removed, remove links, remove @\n","\"\"\""],"metadata":{"id":"bZGc5juw6XAg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(text):\n","\n","    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n","\n","    text = text.lower() # lowercase\n","\n","    text = html.unescape(text) # remove html entities\n","\n","    text =  re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # remove links\n","\n","    text = re.sub(r'@', '', text) # remove @\n","\n","    text = re.sub(r'/', ' ', text) # convert / to space\n","\n","    text = contractions.fix(text) # convert contractions to single words\n","\n","    text = re.sub(r'[^a-z\\s]', '', text) # remove punctuations\n","\n","    return ' '.join(text.split())"],"metadata":{"id":"Hovb7cf985EN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['processed_text'] = df['tweet'].apply(preprocess)"],"metadata":{"id":"6a1hMC2tKnPQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top100_emojis = emojis_array.value_counts()[:100].keys().tolist()"],"metadata":{"id":"0OGpD8MYOCib"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_exp = df.explode('emojis') # explode the emojis list\n","df_exp = df_exp[df_exp['emojis'].isin(top100_emojis)] # keep only top 100 emojis\n","df_final = df_exp.groupby(df_exp.index)['emojis'].apply(list).reset_index() # merge the emojis again\n","df = df.drop(columns='emojis').merge(df_final, left_index=True, right_on='index')[['processed_text', 'emojis']] # filter the df with new df"],"metadata":{"id":"Mj2CcoFzQ6Te"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_csv('/content/drive/MyDrive/emojien/Data/processed_tweets.csv', index=False)"],"metadata":{"id":"gWJN-p7bSsMU"},"execution_count":null,"outputs":[]}]}