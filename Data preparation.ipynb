{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1jHXbWLhZnTmPHhH35_iqUGRsRcQl0AKY","authorship_tag":"ABX9TyP4WuwFoPF9BQxb0LSS2VOZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UxSr3PfossrN"},"outputs":[],"source":["import pandas as pd\n","import html\n","import contractions\n","import unicodedata"]},{"cell_type":"code","source":["pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3I9X5zfNupVu","executionInfo":{"status":"ok","timestamp":1722953519484,"user_tz":-330,"elapsed":8770,"user":{"displayName":"Abhishek maher","userId":"17060706371112675718"}},"outputId":"dc9dc7b6-ef2f-4450-a92d-5de389af31f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.12.2)\n","Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.12.1\n"]}]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/emojien/Data/emojitweets-01-04-2018.txt', 'r') as file: # Downloaded the data file from https://www.kaggle.com/datasets/rexhaif/emojifydata-en\n","    tweets = file.readlines()\n","\n","# Create a DataFrame\n","bigdf = pd.DataFrame(tweets, columns=['tweet'])"],"metadata":{"id":"awKCSQROtErb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del tweets"],"metadata":{"id":"9BHmWK1Y0Fs8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import emoji\n","import re\n","\n","def extract_emojis(text): #function to seperate emojis and text\n","    emojis = emoji.distinct_emoji_list(text)\n","    text = emoji.replace_emoji(text, replace='')\n","    text_without_emojis = ' '.join(text.split())\n","    return text_without_emojis, emojis"],"metadata":{"id":"kkT3pPsSt-cB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = bigdf.sample(1000000) # Choosing a random sample of 10M texts"],"metadata":{"id":"Rk2-Rmv65Q0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[['tweet', 'emojis']] = df['tweet'].apply(lambda x: pd.Series(extract_emojis(x)))"],"metadata":{"id":"BvpAj7bJxKPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emojis_array = df.explode('emojis').dropna()['emojis']"],"metadata":{"id":"Jtln49rdy824"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emojis_array.value_counts()[50:100]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnQJr_a36R2c","executionInfo":{"status":"ok","timestamp":1722957551344,"user_tz":-330,"elapsed":567,"user":{"displayName":"Abhishek maher","userId":"17060706371112675718"}},"outputId":"2369cd7f-bc5d-456c-ec76-62da080befed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["emojis\n","ğŸ˜±        5676\n","ğŸ˜        5548\n","ğŸ’”        5503\n","ğŸŒ¹        5496\n","ğŸ’‹        5430\n","ğŸ’˜        5410\n","ğŸ˜ˆ        5401\n","ğŸ–¤        5244\n","â˜ºï¸       4971\n","ğŸ‘‘        4935\n","ğŸ™ƒ        4900\n","ğŸ’¦        4863\n","ğŸ‘‡        4828\n","Â©        4664\n","ğŸŒ¸        4625\n","ğŸ˜Œ        4624\n","âš¡        4596\n","ğŸ’«        4544\n","ğŸ˜‹        4536\n","ğŸ’        4428\n","ğŸ˜”        4401\n","ğŸ˜’        4193\n","ğŸ“·        3918\n","ğŸ˜†        3842\n","â¡ï¸       3799\n","ğŸ˜œ        3773\n","ğŸ˜€        3765\n","ğŸ‚        3722\n","ğŸ˜¤        3704\n","ğŸ“¸        3637\n","â­        3544\n","ğŸ’°        3536\n","ğŸ™ˆ        3525\n","ğŸ˜„        3520\n","ğŸ¤·ğŸ½â€â™€ï¸    3502\n","ğŸ”´        3465\n","ğŸ¤¤        3428\n","âš½        3424\n","ğŸ˜«        3412\n","ğŸ™‚        3324\n","ğŸ¤§        3272\n","â—        3232\n","ğŸ˜‡        3211\n","ğŸ        3200\n","ğŸ¥        3127\n","â˜€ï¸       3127\n","ğŸ¤ª        3109\n","â„ï¸       3005\n","ğŸ™ğŸ¾       2998\n","ğŸš€        2990\n","Name: count, dtype: int64"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["\"\"\"\n","1. lower case\n","2. remove html entities\n","3. remove links\n","4. remove @\n","2. remove /\n","4. convert contractions to single words\n","2. remove punc\n","3. remove numbers and symbols\n","5. lemmatize\n","observations: html entities are not removed, remove links, remove @\n","\"\"\""],"metadata":{"id":"bZGc5juw6XAg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(text):\n","\n","    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n","\n","    text = text.lower() # lowercase\n","\n","    text = html.unescape(text) # remove html entities\n","\n","    text =  re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # remove links\n","\n","    text = re.sub(r'@', '', text) # remove @\n","\n","    text = re.sub(r'/', ' ', text) # convert / to space\n","\n","    text = contractions.fix(text) # convert contractions to single words\n","\n","    text = re.sub(r'[^a-z\\s]', '', text) # remove punctuations\n","\n","    return ' '.join(text.split())"],"metadata":{"id":"Hovb7cf985EN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['processed_text'] = df['tweet'].apply(preprocess)"],"metadata":{"id":"6a1hMC2tKnPQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top100_emojis = emojis_array.value_counts()[:100].keys().tolist()"],"metadata":{"id":"0OGpD8MYOCib"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_exp = df.explode('emojis') # explode the emojis list\n","df_exp = df_exp[df_exp['emojis'].isin(top100_emojis)] # keep only top 100 emojis\n","df_final = df_exp.groupby(df_exp.index)['emojis'].apply(list).reset_index() # merge the emojis again\n","df = df.drop(columns='emojis').merge(df_final, left_index=True, right_on='index')[['processed_text', 'emojis']] # filter the df with new df"],"metadata":{"id":"Mj2CcoFzQ6Te"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_csv('/content/drive/MyDrive/emojien/Data/processed_tweets.csv', index=False)"],"metadata":{"id":"gWJN-p7bSsMU"},"execution_count":null,"outputs":[]}]}